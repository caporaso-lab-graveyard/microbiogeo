{
 "metadata": {
  "name": "grouping_analysis_workflow"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Define helper functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define various helper functions and their associated tests that will be used in the workflow (and that are not already in QIIME). Run this cell to ensure all required dependencies are installed and setup correctly (e.g. QIIME, numpy) and that all tests pass before running the workflow."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "from csv import writer\n",
      "from os.path import basename, join, splitext\n",
      "from random import sample, shuffle\n",
      "\n",
      "from numpy import mean\n",
      "\n",
      "from qiime.filter import filter_samples_from_distance_matrix\n",
      "from qiime.format import format_distance_matrix\n",
      "from qiime.parse import parse_distmat\n",
      "from qiime.util import MetadataMap\n",
      "\n",
      "# Define functions for manipulating distance matrices.\n",
      "def shuffle_dm(dm_f):\n",
      "    labels, dm_data = parse_distmat(dm_f)\n",
      "    shuffle(labels)\n",
      "    return format_distance_matrix(labels, dm_data)\n",
      "\n",
      "def subsample_dm(dm_f, map_f, category, group_size):\n",
      "    metadata_map = MetadataMap.parseMetadataMap(map_f)\n",
      "    category_map = defaultdict(list)\n",
      "    for samp_id in metadata_map.SampleIds:\n",
      "        category_val = metadata_map.getCategoryValue(samp_id, category)\n",
      "        category_map[category_val].append(samp_id)\n",
      "    \n",
      "    samp_ids_to_keep = []\n",
      "    for category_val, samp_ids in category_map.items():\n",
      "        samp_ids_to_keep.extend(sample(samp_ids, group_size))\n",
      "    return filter_samples_from_distance_matrix(parse_distmat(dm_f), samp_ids_to_keep, negate=True)\n",
      "\n",
      "# TODO These parsing functions are pretty messy... they need to be cleaned up.\n",
      "# Define functions to parse effect size statistics and p-values from the various results files.\n",
      "def parse_anosim_permanova_results(results_f):\n",
      "    for line in results_f:\n",
      "        pass\n",
      "    es, p_value = map(float, line.strip().split('\\t')[1:])\n",
      "    if p_value < 0 or p_value > 1:\n",
      "        raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "    return es, p_value\n",
      "\n",
      "def parse_adonis_results(results_f):\n",
      "    for line in results_f:\n",
      "        if line.startswith('qiime.data$map[[opts$category]]'):\n",
      "            tokens = line.strip().split()\n",
      "            \n",
      "            # The format of the file changes if the result is significant or not.\n",
      "            if len(tokens) == 7:\n",
      "                es, p_value = map(float, line.strip().split()[-2:])\n",
      "                if p_value < 0 or p_value > 1:\n",
      "                    raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "                elif es < 0 or es > 1:\n",
      "                    raise ValueError(\"Encountered invalid R2 value: %.4f\" % es)\n",
      "                return es, p_value\n",
      "            elif len(tokens) == 8:\n",
      "                es, p_value = map(float, line.strip().split()[:-1][-2:])\n",
      "                if p_value < 0 or p_value > 1:\n",
      "                    raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "                elif es < 0 or es > 1:\n",
      "                    raise ValueError(\"Encountered invalid R2 value: %.4f\" % es)\n",
      "                return es, p_value\n",
      "            else:\n",
      "                raise ValueError(\"Encountered unparsable line: %s\" % line)\n",
      "        \n",
      "def parse_mrpp_results(results_f):\n",
      "    for line in results_f:\n",
      "        if line.startswith('Chance corrected within-group agreement A:'):\n",
      "            tokens = line.strip().split()\n",
      "            if len(tokens) == 6:\n",
      "                a_value = float(tokens[-1])\n",
      "            else:\n",
      "                raise ValueError(\"Encountered unparsable line: %s\" % line)\n",
      "        elif line.startswith('Significance of delta:'):\n",
      "            tokens = line.strip().split()\n",
      "            if len(tokens) == 4:\n",
      "                p_value = float(tokens[-1])\n",
      "            else:\n",
      "                raise ValueError(\"Encountered unparsable line: %s\" % line)\n",
      "    if p_value < 0 or p_value > 1:\n",
      "        raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "    return a_value, p_value\n",
      "\n",
      "def parse_dbrda_results(results_f):\n",
      "    for line in results_f:\n",
      "        if line.startswith('Constrained'):\n",
      "            tokens = line.strip().split()\n",
      "            if len(tokens) == 4:\n",
      "                r2 = float(tokens[2])\n",
      "                if r2 < 0 or r2 > 1:\n",
      "                    raise ValueError(\"Encountered invalid R2 value: %.4f\" % r2)\n",
      "            else:\n",
      "                raise ValueError(\"Encountered unparsable line: %s\" % line)\n",
      "        elif line.startswith('Significance:'):\n",
      "            tokens = line.strip().split()\n",
      "            if len(tokens) == 2:\n",
      "                p_value = float(tokens[1])\n",
      "                if p_value < 0 or p_value > 1:\n",
      "                    raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "            else:\n",
      "                raise ValueError(\"Encountered unparsable line: %s\" % line)\n",
      "    return r2, p_value\n",
      "\n",
      "def parse_permdisp_results(results_f):\n",
      "    at_nonparametric_section = False\n",
      "    for line in results_f:\n",
      "        if line.startswith('No. of permutations:'):\n",
      "            at_nonparametric_section = True\n",
      "        elif line.startswith('Groups') and at_nonparametric_section:\n",
      "            tokens = line.strip().split()\n",
      "            if len(tokens) == 7 or len(tokens) == 8:\n",
      "                f_value = float(tokens[4])\n",
      "                p_value = float(tokens[6])\n",
      "                if p_value < 0 or p_value > 1:\n",
      "                    raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "            else:\n",
      "                raise ValueError(\"Encountered unparsable line: %s\" % line)\n",
      "    return f_value, p_value\n",
      "\n",
      "# TODO Put in checks to ensure we are given a float.\n",
      "def format_p_value_as_asterisk(p_value):\n",
      "    # p_value should be a float\n",
      "    result = 'x'\n",
      "    if p_value <= 0.1:\n",
      "        result = '*'\n",
      "    if p_value <= 0.05:\n",
      "        result += '*'\n",
      "    if p_value <= 0.01:\n",
      "        result += '*'\n",
      "    if p_value <= 0.001:\n",
      "        result += '*'\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Set up workflow parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Configure the variables in this section to control how the workflow will be executed. For example, what studies to analyze, categories of interest, etc.."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = True\n",
      "\n",
      "if test:\n",
      "    in_dir = 'test_datasets'\n",
      "    out_dir = 'test_output'\n",
      "    tree_fp = join('test_datasets', 'overview', 'rep_set.tre')\n",
      "    depth_descs = ['5_percent', '25_percent', '50_percent']\n",
      "    studies = {\n",
      "               'overview': {\n",
      "                            'depths': [50, 100, 146],\n",
      "                            'categories': ['Treatment'],\n",
      "                            'group_sizes': [3, 4]\n",
      "                           }\n",
      "              }\n",
      "    #metrics = ['euclidean', 'bray_curtis']\n",
      "    metrics = ['euclidean', 'bray_curtis', 'weighted_unifrac', 'unweighted_unifrac']\n",
      "    grouping_methods = {\n",
      "                        'adonis': parse_adonis_results,\n",
      "                        'anosim': parse_anosim_permanova_results,\n",
      "                        'mrpp': parse_mrpp_results,\n",
      "                        'permanova': parse_anosim_permanova_results,\n",
      "                        'dbrda': parse_dbrda_results,\n",
      "                        'permdisp': parse_permdisp_results\n",
      "                       }\n",
      "    permutations = [99, 999, 9999]\n",
      "    num_shuffled = 3\n",
      "    num_subsampled = 3\n",
      "    jobs_to_start = 2\n",
      "else:\n",
      "    in_dir = 'datasets'\n",
      "    out_dir = 'output'\n",
      "    tree_fp = join('gg_otus_4feb2011', 'trees', 'gg_97_otus_4feb2011.tre')\n",
      "    depth_descs = ['5_percent', '25_percent', '50_percent']\n",
      "    studies = {\n",
      "               '88_soils': {\n",
      "                            'depths': [400, 580, 660],\n",
      "                            'categories': ['ENV_BIOME'],\n",
      "                            'group_sizes': [5, 10, 20, 40]\n",
      "                           }, \n",
      "               'glen_canyon': {\n",
      "                               'depths': [15000, 29000, 53000],\n",
      "                               'categories': ['CurrentlyWet'],\n",
      "                               'group_sizes': [5, 10, 20, 40]\n",
      "                              },\n",
      "               'keyboard': {\n",
      "                            'depths': [390, 780, 1015],\n",
      "                            'categories': ['HOST_SUBJECT_ID'],\n",
      "                            'group_sizes': [5, 10, 20, 40]\n",
      "                           },\n",
      "               'whole_body': {\n",
      "                              'depths': [575, 877, 1110],\n",
      "                              'categories': ['BODY_SITE', 'SEX'],\n",
      "                              'group_sizes': [5, 10, 20, 40]\n",
      "                             }\n",
      "              }\n",
      "    metrics = ['euclidean', 'bray_curtis', 'weighted_unifrac', 'unweighted_unifrac']\n",
      "    grouping_methods = {\n",
      "                        'adonis': parse_adonis_results,\n",
      "                        'anosim': parse_anosim_permanova_results,\n",
      "                        'mrpp': parse_mrpp_results,\n",
      "                        'permanova': parse_anosim_permanova_results,\n",
      "                        'dbrda': parse_dbrda_results,\n",
      "                        'permdisp': parse_permdisp_results\n",
      "                       }\n",
      "    permutations = [99, 999, 9999]\n",
      "    num_shuffled = 3\n",
      "    num_subsampled = 3\n",
      "    jobs_to_start = 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Generate distance matrices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate distance matrices for each study at even sampling depths that exclude 5%, 25%, and 50% of the samples from the input OTU table (these numbers were calculated beforehand). Generate Euclidean, Bray-Curtis, weighted UniFrac, and unweighted UniFrac distance matrices at each sampling depth using the GreenGenes 97% tree. Also generate several shuffled versions of each distance matrix, which can be used later as negative controls.\n",
      "\n",
      "In addition, generate several subsampled versions of each distance matrix to control the size of each group of samples (based on a category), which can be used later to test how the methods perform on different study sizes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "!mkdir $out_dir\n",
      "for study in studies:\n",
      "    in_study_dir = join(in_dir, study)\n",
      "    out_study_dir = join(out_dir, study)\n",
      "    !mkdir $out_study_dir\n",
      "    !cp $in_study_dir/map.txt $out_study_dir/\n",
      "    map_fp = join(out_study_dir, 'map.txt')\n",
      "    \n",
      "    for depth in studies[study]['depths']:\n",
      "        full_otu_fp = join(in_study_dir, 'otu_table.biom')\n",
      "        even_otu_fp = join(out_study_dir, 'otu_table_even%d.biom' % depth)\n",
      "        bdiv_out_dir = join(out_study_dir, 'bdiv_even%d' % depth)\n",
      "        \n",
      "        metrics_param = ','.join(metrics)\n",
      "        !single_rarefaction.py -i $full_otu_fp -o $even_otu_fp -d $depth\n",
      "        !parallel_beta_diversity.py -i $even_otu_fp -o $bdiv_out_dir -m $metrics_param -T -t $tree_fp -O $jobs_to_start\n",
      "        \n",
      "        # Rename each file to match QIIME's standard naming conventions of distance matrices. Generate shuffled versions of each distance matrix.\n",
      "        for metric in metrics:\n",
      "            dm_fp = join(bdiv_out_dir, '%s_otu_table_even%d.txt' % (metric, depth))\n",
      "            renamed_dm_fp = join(bdiv_out_dir, '%s_dm.txt' % metric)\n",
      "            !mv $dm_fp $renamed_dm_fp\n",
      "            for i in range(1, num_shuffled + 1):\n",
      "                renamed_dm_f = open(renamed_dm_fp, 'U')\n",
      "                shuffled_dm_fp = join(bdiv_out_dir, '%s_dm_shuffled%d.txt' % (metric, i))\n",
      "                shuffled_dm_f = open(shuffled_dm_fp, 'w')\n",
      "                shuffled_dm_f.write(shuffle_dm(renamed_dm_f))\n",
      "                shuffled_dm_f.close()\n",
      "                renamed_dm_f.close()\n",
      "            \n",
      "            # Create subsampled distance matrices.\n",
      "            for category in studies[study]['categories']:\n",
      "                for group_size in studies[study]['group_sizes']:\n",
      "                    for i in range(1, num_subsampled + 1):\n",
      "                        subsampled_dm_fp = join(bdiv_out_dir, '%s_dm_%s_ss%d_%d.txt' % (metric, category, group_size, i))\n",
      "                        subsampled_dm = open(subsampled_dm_fp, 'w')\n",
      "                        subsampled_dm.write(subsample_dm(open(renamed_dm_fp, 'U'), open(map_fp, 'U'), category, group_size))\n",
      "                        subsampled_dm.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Run grouping analysis methods"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run each *grouping analysis* statistical method on each distance matrix. These are methods that test out categorical variables such as sex, individual, body site, etc.."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for study in studies:\n",
      "    study_dir = join(out_dir, study)\n",
      "    map_fp = join(study_dir, 'map.txt')\n",
      "    categories = studies[study]['categories']\n",
      "    \n",
      "    for depth in studies[study]['depths']:\n",
      "        depth_dir = join(study_dir, 'bdiv_even%d' % depth)\n",
      "        dm_wildcard = join(depth_dir, '*_dm*.txt')\n",
      "        dm_fps = !ls $dm_wildcard\n",
      "        \n",
      "        for dm_fp in dm_fps:\n",
      "            for method in grouping_methods:\n",
      "                for category in categories:\n",
      "                    for permutation in permutations:\n",
      "                        dm_bn = basename(dm_fp)\n",
      "                        if 'dm.txt' in dm_bn or 'dm_shuffled' in dm_bn or 'dm_%s_ss' % category in dm_bn:\n",
      "                            results_dir = join(depth_dir, '%s_%s_%s_%d' % (splitext(dm_bn)[0], method, category, permutation))\n",
      "                            !compare_categories.py --method $method -n $permutation -i $dm_fp -m $map_fp -c $category -o $results_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Collate results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Parse and collect the effect size statistics and p-values from each of the tests that were run. The resulting data structure can then be used to format result tables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = {}\n",
      "for depth_idx, depth_desc in enumerate(depth_descs):\n",
      "    depth_res = {}\n",
      "    for metric in metrics:\n",
      "        metric_res = {}\n",
      "        for method, res_parsing_fn in grouping_methods.items():\n",
      "            method_res = {}\n",
      "            for study in studies:\n",
      "                study_res = {}\n",
      "                \n",
      "                # Figure out what our actual depth is for the study, and what subsampled group sizes we performed.\n",
      "                depth = studies[study]['depths'][depth_idx]\n",
      "                group_sizes = studies[study]['group_sizes']\n",
      "                \n",
      "                for category in studies[study]['categories']:\n",
      "                    category_res = {}\n",
      "                    full_ess = []\n",
      "                    full_p_vals = []\n",
      "                    shuff_ess = []\n",
      "                    shuff_p_vals = []\n",
      "                    \n",
      "                    # TODO This next part is pretty messy... it needs to get cleaned up.\n",
      "                    for permutation in permutations:\n",
      "                        # Collect results for full distance matrices.\n",
      "                        full_res_f = open(join(out_dir, study, 'bdiv_even%d' % depth, '%s_dm_%s_%s_%d' % (metric, method, category, permutation), '%s_results.txt' % method), 'U')\n",
      "                        full_es, full_p_val = res_parsing_fn(full_res_f)\n",
      "                        full_res_f.close()\n",
      "                        full_ess.append(full_es)\n",
      "                        full_p_vals.append(full_p_val)\n",
      "                        \n",
      "                        # Collect results for shuffled distance matrices.\n",
      "                        avg_shuff_ess = []\n",
      "                        avg_shuff_p_vals = []\n",
      "                        for shuff_num in range(1, num_shuffled + 1):\n",
      "                            shuff_res_f = open(join(out_dir, study, 'bdiv_even%d' % depth, '%s_dm_shuffled%d_%s_%s_%d' % (metric, shuff_num, method, category, permutation), '%s_results.txt' % method), 'U')\n",
      "                            shuff_es, shuff_p_val = res_parsing_fn(shuff_res_f)\n",
      "                            shuff_res_f.close()\n",
      "                            avg_shuff_ess.append(shuff_es)\n",
      "                            avg_shuff_p_vals.append(shuff_p_val)\n",
      "                        shuff_ess.append(mean(avg_shuff_ess))\n",
      "                        shuff_p_vals.append(mean(avg_shuff_p_vals))\n",
      "                        \n",
      "                    if len(set(full_ess)) != 1 or len(set(shuff_ess)) != 1:\n",
      "                        raise ValueError(\"The effect size statistics were not the same for different numbers of permutations. Something went wrong...\")\n",
      "                    for p_val in full_p_vals:\n",
      "                        if p_val < 0 or p_val > 1:\n",
      "                            raise ValueError(\"Encountered invalid p-value: %.4f\" % p_val)\n",
      "                    for p_val in shuff_p_vals:\n",
      "                        if p_val < 0 or p_val > 1:\n",
      "                            raise ValueError(\"Encountered invalid p-value: %.4f\" % p_val)\n",
      "                    category_res['full'] = (full_ess[0], full_p_vals)\n",
      "                    category_res['shuffled'] = (shuff_ess[0], shuff_p_vals)\n",
      "                        \n",
      "                    # Collect results for subsampled distance matrices.\n",
      "                    ss_ess = []\n",
      "                    ss_p_vals = []\n",
      "                    for group_size in group_sizes:\n",
      "                        gs_ess = []\n",
      "                        gs_p_vals = []\n",
      "                        \n",
      "                        for permutation in permutations:\n",
      "                            avg_ss_ess = []\n",
      "                            avg_ss_p_vals = []\n",
      "                            for ss_num in range(1, num_subsampled + 1):\n",
      "                                ss_res_f = open(join(out_dir, study, 'bdiv_even%d' % depth, '%s_dm_%s_ss%d_%d_%s_%s_%d' % (metric, category, group_size, ss_num, method, category, permutation),\n",
      "                                                     '%s_results.txt' % method), 'U')\n",
      "                                ss_es, ss_p_val = res_parsing_fn(ss_res_f)\n",
      "                                ss_res_f.close()\n",
      "                                avg_ss_ess.append(ss_es)\n",
      "                                avg_ss_p_vals.append(ss_p_val)\n",
      "                            gs_ess.append(mean(avg_ss_ess))\n",
      "                            gs_p_vals.append(mean(avg_ss_p_vals))\n",
      "                        \n",
      "                        if len(set(gs_ess)) != 1:\n",
      "                            raise ValueError(\"The effect size statistics were not the same for different numbers of permutations. Something went wrong...\")\n",
      "                        for p_val in gs_p_vals:\n",
      "                            if p_val < 0 or p_val > 1:\n",
      "                                raise ValueError(\"Encountered invalid p-value: %.4f\" % p_val)\n",
      "                        ss_ess.append(gs_ess[0])\n",
      "                        ss_p_vals.append(gs_p_vals)\n",
      "                    \n",
      "                    if len(ss_ess) != len(ss_p_vals):\n",
      "                        raise ValueError(\"We don't have the same number of effect size statistics as p-values. Something went wrong...\")\n",
      "                    category_res['subsampled'] = (ss_ess, ss_p_vals)\n",
      "                    \n",
      "                    study_res[category] = category_res\n",
      "                method_res[study] = study_res\n",
      "            metric_res[method] = method_res\n",
      "        depth_res[metric] = metric_res\n",
      "    results[depth_desc] = depth_res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Build results summary tables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Build tables to summarize the results of the statistical methods. These tables will be in TSV format so that they can be easily imported into Excel for viewing and cleanup for publication."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for depth_desc, depth_res in results.items():\n",
      "    for metric, metric_res in depth_res.items():\n",
      "        constructed_header = False\n",
      "        header = ['Method']\n",
      "        rows = []\n",
      "        for method, method_res in sorted(metric_res.items()):\n",
      "            row = ['%s' % method]\n",
      "            for study, study_res in sorted(method_res.items()):\n",
      "                for category, category_res in sorted(study_res.items()):\n",
      "                    # Format full results.\n",
      "                    header.append('%s\\r%s' % (study, category))\n",
      "                    row.append('%.2f; %s' % (category_res['full'][0], ', '.join(map(format_p_value_as_asterisk, category_res['full'][1]))))\n",
      "                    \n",
      "                    # Format shuffled results.\n",
      "                    header.append('%s\\r%s (shuffled)' % (study, category))\n",
      "                    row.append('%.2f; %s' % (category_res['shuffled'][0], ', '.join(map(format_p_value_as_asterisk, category_res['shuffled'][1]))))\n",
      "                    \n",
      "                    # Format subsampled results.\n",
      "                    header.append('%s\\r%s (subsampled)' % (study, category))\n",
      "                    cell = ['%.2f; %s' % (es, ', '.join(map(format_p_value_as_asterisk, p_vals))) for es, p_vals in zip(*category_res['subsampled'])]\n",
      "                    row.append('\\r'.join(cell))\n",
      "            if not constructed_header:\n",
      "                rows.append(header[:])\n",
      "                constructed_header = True\n",
      "            rows.append(row)\n",
      "        with open(join(out_dir, 'grouping_analysis_method_comparison_table_%s_%s.txt' % (depth_desc, metric)), 'wb') as out_f:\n",
      "            # We use \\r so that we can force linebreaks within cells when imported into Excel. Not sure if this will work with other spreadsheet programs such as Open Office.\n",
      "            tsv_writer = writer(out_f, delimiter='\\t', lineterminator='\\r')\n",
      "            tsv_writer.writerows(rows)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# For testing...\n",
      "f1 = [\"Method Name\\tR-value\\tP-value\\n\", \"ANOSIM\\t0.463253142506\\t0.01\\n\"]\n",
      "a, b = parse_anosim_permanova_results(f1)\n",
      "print a\n",
      "print b\n",
      "print ''\n",
      "\n",
      "f1 = \"\"\"\n",
      "Call:\n",
      "adonis(formula = as.dist(qiime.data$distmat) ~ qiime.data$map[[opts$category]],      permutations = opts$num_permutations) \n",
      "\n",
      "                                Df SumsOfSqs MeanSqs F.Model      R2 Pr(>F)   \n",
      "qiime.data$map[[opts$category]]  6     6.635 1.10591  3.2632 0.20273   0.01 **\n",
      "Residuals                       77    26.096 0.33891         0.79727          \n",
      "Total                           83    32.731                 1.00000          \n",
      "---\n",
      "Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\"\"\".split('\\n')\n",
      "\n",
      "a, b = parse_adonis_results(f1)\n",
      "print a\n",
      "print b\n",
      "print ''\n",
      "\n",
      "f1 = \"\"\"\n",
      "Call:\n",
      "mrpp(dat = as.dist(qiime.data$distmat), grouping = qiime.data$map[[opts$category]],      permutations = opts$num_permutations) \n",
      "\n",
      "Dissimilarity index: \n",
      "Weights for groups:  n \n",
      "\n",
      "Class means and counts:\n",
      "\n",
      "      ENVO:forest ENVO:grassland ENVO:shrubland\n",
      "delta 0.8133      0.8758         0.8456        \n",
      "n     13          6              20            \n",
      "      ENVO:Temperate broadleaf and mixed forest biome ENVO:Temperate grasslands\n",
      "delta 0.7626                                          0.8554                   \n",
      "n     19                                              11                       \n",
      "      ENVO:Tropical and subtropical grasslands, savannas, and shrubland biome\n",
      "delta 0.8392                                                                 \n",
      "n     3                                                                      \n",
      "      ENVO:Tropical humid forests\n",
      "delta 0.7835                     \n",
      "n     12                         \n",
      "\n",
      "Chance corrected within-group agreement A: 0.07567 \n",
      "Based on observed delta 0.8162 and expected delta 0.883 \n",
      "\n",
      "Significance of delta: 0.01 \n",
      "Based on  99  permutations\n",
      "\"\"\".split('\\n')\n",
      "\n",
      "a, b = parse_mrpp_results(f1)\n",
      "print a\n",
      "print b\n",
      "print ''\n",
      "\n",
      "f1 = \"\"\"Call: capscale(formula = as.dist(qiime.data$distmat) ~ factor, data =\n",
      "factors.frame)\n",
      "\n",
      "               Inertia Proportion Rank\n",
      "Total         159.1762                \n",
      "Real Total    165.4413     1.0000     \n",
      "Constrained    46.0873     0.2786   19\n",
      "Unconstrained 119.3540     0.7214  371\n",
      "Imaginary      -6.2651             213\n",
      "Inertia is squared Unknown distance \n",
      "\n",
      "Eigenvalues for constrained axes:\n",
      "    CAP1     CAP2     CAP3     CAP4     CAP5     CAP6     CAP7     CAP8 \n",
      "14.72239 10.95891  8.89776  3.26489  2.89957  1.41151  0.87627  0.69475 \n",
      "    CAP9    CAP10    CAP11    CAP12    CAP13    CAP14    CAP15    CAP16 \n",
      " 0.40960  0.35446  0.29999  0.24395  0.20137  0.18342  0.17567  0.15110 \n",
      "   CAP17    CAP18    CAP19 \n",
      " 0.13347  0.11498  0.09327 \n",
      "\n",
      "Eigenvalues for unconstrained axes:\n",
      "  MDS1   MDS2   MDS3   MDS4   MDS5   MDS6   MDS7   MDS8 \n",
      "12.480  5.688  4.495  3.722  3.331  2.814  2.279  2.153 \n",
      "(Showed only 8 of all 371 unconstrained eigenvalues)\n",
      "\n",
      "\n",
      "Permutation test for capscale \n",
      "\n",
      "Call: capscale(formula = as.dist(qiime.data$distmat) ~ factor, data =\n",
      "factors.frame)\n",
      "Permutation test for all constrained eigenvalues\n",
      "Pseudo-F:\t 11.48258 (with 19, 565 Degrees of Freedom)\n",
      "Significance:\t 0.010101 \n",
      "Based on 98 permutations under reduced model.\n",
      "\"\"\".split('\\n')\n",
      "\n",
      "r2, p_val = parse_dbrda_results(f1)\n",
      "print r2\n",
      "print p_val\n",
      "print ''\n",
      "\n",
      "f1 = \"\"\"Analysis of Variance Table\n",
      "\n",
      "Response: Distances\n",
      "           Df Sum Sq   Mean Sq F value Pr(>F)\n",
      "Groups      1 0.0119 0.0118769  2.0989 0.1479\n",
      "Residuals 583 3.2990 0.0056587               \n",
      "\n",
      "Permutation test for homogeneity of multivariate dispersions\n",
      "\n",
      "No. of permutations: 999  \n",
      "\n",
      "**** STRATA ****\n",
      "Permutations are unstratified\n",
      "\n",
      "**** SAMPLES ****\n",
      "Permutation type: free \n",
      "Mirrored permutations for Samples?: No \n",
      "\n",
      "Response: Distances\n",
      "           Df Sum Sq   Mean Sq      F N.Perm Pr(>F)\n",
      "Groups      1 0.0119 0.0118769 2.0989    999  0.131\n",
      "Residuals 583 3.2990 0.0056587                     \n",
      "\n",
      "Pairwise comparisons:\n",
      "(Observed p-value below diagonal, permuted p-value above diagonal)\n",
      "        female  male\n",
      "female         0.132\n",
      "male   0.14794  \n",
      "\"\"\".split('\\n')\n",
      "\n",
      "f_val, p_val = parse_permdisp_results(f1)\n",
      "print f_val\n",
      "print p_val\n",
      "print ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.463253142506\n",
        "0.01\n",
        "\n",
        "0.20273\n",
        "0.01\n",
        "\n",
        "0.07567\n",
        "0.01\n",
        "\n",
        "0.2786\n",
        "0.010101\n",
        "\n",
        "2.0989\n",
        "0.131\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 32
    }
   ],
   "metadata": {}
  }
 ]
}