{
 "metadata": {
  "name": "grouping_analysis_workflow"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Define helper functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define various helper functions and their associated tests that will be used in the workflow (and that are not already in QIIME). Run this cell to ensure all required dependencies are installed and setup correctly (e.g. QIIME, numpy) and that all tests pass before running the workflow."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from csv import writer\n",
      "from os.path import join\n",
      "\n",
      "from IPython.parallel import Client\n",
      "\n",
      "from numpy import mean, median\n",
      "\n",
      "# Define functions for manipulating distance matrices.\n",
      "def shuffle_dm(dm_f):\n",
      "    from qiime.parse import parse_distmat\n",
      "    from random import shuffle\n",
      "    from qiime.format import format_distance_matrix\n",
      "    \n",
      "    labels, dm_data = parse_distmat(dm_f)\n",
      "    shuffle(labels)\n",
      "    return format_distance_matrix(labels, dm_data)\n",
      "\n",
      "def subsample_dm(dm_f, map_f, category, max_group_size):\n",
      "    from collections import defaultdict\n",
      "    from random import sample\n",
      "    from qiime.filter import filter_samples_from_distance_matrix\n",
      "    from qiime.parse import parse_distmat\n",
      "    from qiime.util import MetadataMap\n",
      "    \n",
      "    dm_labels, dm_data = parse_distmat(dm_f)\n",
      "    metadata_map = MetadataMap.parseMetadataMap(map_f)\n",
      "    category_map = defaultdict(list)\n",
      "    for samp_id in metadata_map.SampleIds:\n",
      "        # Mapping files can have more samples than distance matrices, which can happen in this case since we are\n",
      "        # dealing with rarefied OTU tables (samples get dropped).\n",
      "        if samp_id in dm_labels:\n",
      "            category_val = metadata_map.getCategoryValue(samp_id, category)\n",
      "            category_map[category_val].append(samp_id)\n",
      "    \n",
      "    samp_ids_to_keep = []\n",
      "    for category_val, samp_ids in category_map.items():\n",
      "        samp_ids_to_keep.extend(sample(samp_ids, min(max_group_size, len(samp_ids))))\n",
      "    return filter_samples_from_distance_matrix((dm_labels, dm_data), samp_ids_to_keep, negate=True)\n",
      "\n",
      "# TODO These parsing functions are pretty messy... they need to be cleaned up.\n",
      "# Define functions to parse effect size statistics and p-values from the various results files.\n",
      "def parse_anosim_permanova_results(results_f):\n",
      "    for line in results_f:\n",
      "        pass\n",
      "    es, p_value = line.strip().split('\\t')[1:]\n",
      "    es = float(es)\n",
      "    if 'Too few iters to compute p-value' in p_value:\n",
      "        p_value = None\n",
      "    else:\n",
      "        p_value = float(p_value)\n",
      "        if p_value < 0 or p_value > 1:\n",
      "            raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "    return es, p_value\n",
      "\n",
      "def parse_adonis_results(results_f):\n",
      "    for line in results_f:\n",
      "        if line.startswith('qiime.data$map[[opts$category]]'):\n",
      "            tokens = line.strip().split()\n",
      "            \n",
      "            # The format of the file changes if the result is significant or not.\n",
      "            if len(tokens) == 7:\n",
      "                es, p_value = map(float, line.strip().split()[-2:])\n",
      "                if p_value < 0 or p_value > 1:\n",
      "                    raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "                elif es < 0 or es > 1:\n",
      "                    raise ValueError(\"Encountered invalid R2 value: %.4f\" % es)\n",
      "                return es, p_value\n",
      "            elif len(tokens) == 8:\n",
      "                es, p_value = map(float, line.strip().split()[:-1][-2:])\n",
      "                if p_value < 0 or p_value > 1:\n",
      "                    raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "                elif es < 0 or es > 1:\n",
      "                    raise ValueError(\"Encountered invalid R2 value: %.4f\" % es)\n",
      "                return es, p_value\n",
      "            else:\n",
      "                raise ValueError(\"Encountered unparsable line: %s\" % line)\n",
      "        \n",
      "def parse_mrpp_results(results_f):\n",
      "    for line in results_f:\n",
      "        if line.startswith('Chance corrected within-group agreement A:'):\n",
      "            tokens = line.strip().split()\n",
      "            if len(tokens) == 6:\n",
      "                a_value = float(tokens[-1])\n",
      "            else:\n",
      "                raise ValueError(\"Encountered unparsable line: %s\" % line)\n",
      "        elif line.startswith('Significance of delta:'):\n",
      "            tokens = line.strip().split()\n",
      "            if len(tokens) == 4:\n",
      "                p_value = float(tokens[-1])\n",
      "            else:\n",
      "                raise ValueError(\"Encountered unparsable line: %s\" % line)\n",
      "    if p_value < 0 or p_value > 1:\n",
      "        raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "    return a_value, p_value\n",
      "\n",
      "def parse_dbrda_results(results_f):\n",
      "    for line in results_f:\n",
      "        if line.startswith('Constrained'):\n",
      "            tokens = line.strip().split()\n",
      "            if len(tokens) == 4:\n",
      "                r2 = float(tokens[2])\n",
      "                if r2 < 0 or r2 > 1:\n",
      "                    raise ValueError(\"Encountered invalid R2 value: %.4f\" % r2)\n",
      "            else:\n",
      "                raise ValueError(\"Encountered unparsable line: %s\" % line)\n",
      "        elif line.startswith('Significance:'):\n",
      "            tokens = line.strip().split()\n",
      "            if len(tokens) == 2:\n",
      "                p_value = float(tokens[1])\n",
      "                if p_value < 0 or p_value > 1:\n",
      "                    raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "            else:\n",
      "                raise ValueError(\"Encountered unparsable line: %s\" % line)\n",
      "    return r2, p_value\n",
      "\n",
      "def parse_permdisp_results(results_f):\n",
      "    at_nonparametric_section = False\n",
      "    for line in results_f:\n",
      "        if line.startswith('No. of permutations:'):\n",
      "            at_nonparametric_section = True\n",
      "        elif line.startswith('Groups') and at_nonparametric_section:\n",
      "            tokens = line.strip().split()\n",
      "            if len(tokens) == 7 or len(tokens) == 8:\n",
      "                f_value = float(tokens[4])\n",
      "                p_value = float(tokens[6])\n",
      "                if p_value < 0 or p_value > 1:\n",
      "                    raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "            else:\n",
      "                raise ValueError(\"Encountered unparsable line: %s\" % line)\n",
      "    return f_value, p_value\n",
      "\n",
      "# TODO Put in checks to ensure we are given a float.\n",
      "def format_p_value_as_asterisk(p_value):\n",
      "    # p_value should be a float\n",
      "    result = 'x'\n",
      "    if p_value <= 0.1:\n",
      "        result = '*'\n",
      "    if p_value <= 0.05:\n",
      "        result += '*'\n",
      "    if p_value <= 0.01:\n",
      "        result += '*'\n",
      "    if p_value <= 0.001:\n",
      "        result += '*'\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Set up workflow parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Configure the variables in this section to control how the workflow will be executed. For example, what studies to analyze, categories of interest, etc.."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = False\n",
      "\n",
      "if test:\n",
      "    in_dir = 'test_datasets'\n",
      "    out_dir = 'test_grouping_analysis_output'\n",
      "    tree_fp = join('test_datasets', 'overview', 'rep_set.tre')\n",
      "    depth_descs = ['5_percent', '25_percent', '50_percent']\n",
      "    studies = {\n",
      "               'overview': {\n",
      "                            'depths': [50, 100, 146],\n",
      "                            'categories': ['Treatment'],\n",
      "                            'group_sizes': [3, 4]\n",
      "                           },\n",
      "               'overview2': {\n",
      "                             'depths': [50, 100, 146],\n",
      "                             'categories': ['Treatment'],\n",
      "                             'group_sizes': [3, 4]\n",
      "                            }\n",
      "              }\n",
      "    metrics = ['euclidean', 'bray_curtis']\n",
      "    grouping_methods = {\n",
      "                        'adonis': parse_adonis_results,\n",
      "                        'anosim': parse_anosim_permanova_results\n",
      "                       }\n",
      "    permutations = [99, 999]\n",
      "    num_shuffled = 2\n",
      "    num_subsampled = 2\n",
      "else:\n",
      "    in_dir = 'datasets'\n",
      "    out_dir = 'grouping_analysis_output'\n",
      "    tree_fp = join('gg_otus_4feb2011', 'trees', 'gg_97_otus_4feb2011.tre')\n",
      "    depth_descs = ['5_percent', '25_percent', '50_percent']\n",
      "    studies = {\n",
      "               '88_soils': {\n",
      "                            'depths': [400, 580, 660],\n",
      "                            'categories': ['ENV_BIOME'],\n",
      "                            'group_sizes': [5, 10, 20, 40]\n",
      "                           }, \n",
      "               'glen_canyon': {\n",
      "                               'depths': [15000, 29000, 53000],\n",
      "                               'categories': ['CurrentlyWet'],\n",
      "                               'group_sizes': [5, 10, 20, 40]\n",
      "                              },\n",
      "               'keyboard': {\n",
      "                            'depths': [390, 780, 1015],\n",
      "                            'categories': ['HOST_SUBJECT_ID'],\n",
      "                            'group_sizes': [5, 10, 20, 40]\n",
      "                           },\n",
      "               'whole_body': {\n",
      "                              'depths': [575, 877, 1110],\n",
      "                              'categories': ['BODY_SITE', 'SEX'],\n",
      "                              'group_sizes': [5, 10, 20, 40]\n",
      "                             }\n",
      "              }\n",
      "    metrics = ['euclidean', 'bray_curtis', 'weighted_unifrac', 'unweighted_unifrac']\n",
      "    grouping_methods = {\n",
      "                        'adonis': parse_adonis_results,\n",
      "                        'anosim': parse_anosim_permanova_results,\n",
      "                        'mrpp': parse_mrpp_results,\n",
      "                        'permanova': parse_anosim_permanova_results,\n",
      "                        'dbrda': parse_dbrda_results,\n",
      "                        'permdisp': parse_permdisp_results\n",
      "                       }\n",
      "    permutations = [99, 999]\n",
      "    num_shuffled = 5\n",
      "    num_subsampled = 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Generate distance matrices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate distance matrices for each study at even sampling depths that exclude 5%, 25%, and 50% of the samples from the input OTU table (these numbers were calculated beforehand). Generate Euclidean, Bray-Curtis, weighted UniFrac, and unweighted UniFrac distance matrices at each sampling depth using the GreenGenes 97% tree. Also generate several shuffled versions of each distance matrix, which can be used later as negative controls.\n",
      "\n",
      "In addition, generate several subsampled versions of each distance matrix to control the size of each group of samples (based on a category), which can be used later to test how the methods perform on different study sizes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# The parameters need to be wrapped in parens in order to work with map.\n",
      "def generate_per_study_depth_dms((study, depth, metrics, categories, group_sizes, num_shuffled, num_subsampled, in_dir, out_dir, tree_fp, shuffle_dm_fn,\n",
      "                                  subsample_dm_fn)):\n",
      "    from os.path import join\n",
      "    \n",
      "    in_study_dir = join(in_dir, study)\n",
      "    out_study_dir = join(out_dir, study)\n",
      "    !mkdir $out_study_dir\n",
      "    !cp $in_study_dir/map.txt $out_study_dir/\n",
      "    map_fp = join(out_study_dir, 'map.txt')\n",
      "    \n",
      "    full_otu_fp = join(in_study_dir, 'otu_table.biom')\n",
      "    even_otu_fp = join(out_study_dir, 'otu_table_even%d.biom' % depth)\n",
      "    bdiv_out_dir = join(out_study_dir, 'bdiv_even%d' % depth)\n",
      "    \n",
      "    metrics_param = ','.join(metrics)\n",
      "    !single_rarefaction.py -i $full_otu_fp -o $even_otu_fp -d $depth\n",
      "    !beta_diversity.py -i $even_otu_fp -o $bdiv_out_dir -m $metrics_param -t $tree_fp\n",
      "    \n",
      "    # Rename each file to match QIIME's standard naming conventions of distance matrices. Generate shuffled versions of each distance matrix.\n",
      "    for metric in metrics:\n",
      "        dm_fp = join(bdiv_out_dir, '%s_otu_table_even%d.txt' % (metric, depth))\n",
      "        renamed_dm_fp = join(bdiv_out_dir, '%s_dm.txt' % metric)\n",
      "        !mv $dm_fp $renamed_dm_fp\n",
      "        for i in range(1, num_shuffled + 1):\n",
      "            renamed_dm_f = open(renamed_dm_fp, 'U')\n",
      "            shuffled_dm_fp = join(bdiv_out_dir, '%s_dm_shuffled%d.txt' % (metric, i))\n",
      "            shuffled_dm_f = open(shuffled_dm_fp, 'w')\n",
      "            shuffled_dm_f.write(shuffle_dm_fn(renamed_dm_f))\n",
      "            shuffled_dm_f.close()\n",
      "            renamed_dm_f.close()\n",
      "        \n",
      "        # Create subsampled distance matrices.\n",
      "        for category in categories:\n",
      "            for group_size in group_sizes:\n",
      "                for i in range(1, num_subsampled + 1):\n",
      "                    subsampled_dm_fp = join(bdiv_out_dir, '%s_dm_%s_ss%d_%d.txt' % (metric, category, group_size, i))\n",
      "                    subsampled_dm = open(subsampled_dm_fp, 'w')\n",
      "                    subsampled_dm.write(subsample_dm_fn(open(renamed_dm_fp, 'U'), open(map_fp, 'U'), category, group_size))\n",
      "                    subsampled_dm.close()\n",
      "\n",
      "# Process each depth in each study in parallel.\n",
      "c = Client()\n",
      "dview = c[:]\n",
      "dview.block = True\n",
      "\n",
      "!mkdir $out_dir\n",
      "per_study_depths = []\n",
      "for study in studies:\n",
      "    for depth in studies[study]['depths']:\n",
      "        per_study_depths.append((study, depth, metrics, studies[study]['categories'], studies[study]['group_sizes'], num_shuffled, num_subsampled,\n",
      "                                 in_dir, out_dir, tree_fp, shuffle_dm, subsample_dm))\n",
      "out = dview.map(generate_per_study_depth_dms, per_study_depths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Run grouping analysis methods"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run each *grouping analysis* statistical method on each distance matrix. These are methods that test out categorical variables such as sex, individual, body site, etc.."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import listdir\n",
      "from os.path import basename, exists, join, splitext\n",
      "from random import shuffle\n",
      "\n",
      "def run_compare_categories((method, category, permutation, dm_fp, map_fp, results_dir)):\n",
      "    !compare_categories.py --method $method -n $permutation -i $dm_fp -m $map_fp -c $category -o $results_dir\n",
      "\n",
      "jobs = []\n",
      "for study in studies:\n",
      "    for depth in studies[study]['depths']:\n",
      "        for method in grouping_methods:\n",
      "            study_dir = join(out_dir, study)\n",
      "            map_fp = join(study_dir, 'map.txt')\n",
      "            depth_dir = join(study_dir, 'bdiv_even%d' % depth)\n",
      "            dm_wildcard = join(depth_dir, '*_dm*.txt')\n",
      "            dm_fps = !ls $dm_wildcard\n",
      "            \n",
      "            for dm_fp in dm_fps:\n",
      "                for category in studies[study]['categories']:\n",
      "                    for permutation in permutations:\n",
      "                        dm_bn = basename(dm_fp)\n",
      "                        if 'dm.txt' in dm_bn or 'dm_shuffled' in dm_bn or 'dm_%s_ss' % category in dm_bn:\n",
      "                            results_dir = join(depth_dir, '%s_%s_%s_%d' % (splitext(dm_bn)[0], method, category, permutation))\n",
      "                            \n",
      "                            # Skip the job if the results dir exists and is not empty. We'll assume it was created from a previous run.\n",
      "                            if not exists(results_dir) or len(listdir(results_dir)) == 0:\n",
      "                                jobs.append((method, category, permutation, dm_fp, map_fp, results_dir))\n",
      "\n",
      "# Process compare_category.py runs in parallel.\n",
      "c = Client()\n",
      "dview = c[:]\n",
      "dview.block = True\n",
      "\n",
      "# We shuffle the jobs to (hopefully) get spread out the longer-running jobs over IPython engines (e.g. whole body @ 999 permutations).\n",
      "shuffle(jobs)\n",
      "out = dview.map(run_compare_categories, jobs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "1238"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Collate results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Parse and collect the effect size statistics and p-values from each of the tests that were run. The resulting data structure can then be used to format result tables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = {}\n",
      "for depth_idx, depth_desc in enumerate(depth_descs):\n",
      "    depth_res = {}\n",
      "    for metric in metrics:\n",
      "        metric_res = {}\n",
      "        for method, res_parsing_fn in grouping_methods.items():\n",
      "            method_res = {}\n",
      "            for study in studies:\n",
      "                study_res = {}\n",
      "                \n",
      "                # Figure out what our actual depth is for the study, and what subsampled group sizes we performed.\n",
      "                depth = studies[study]['depths'][depth_idx]\n",
      "                group_sizes = studies[study]['group_sizes']\n",
      "                \n",
      "                for category in studies[study]['categories']:\n",
      "                    category_res = {}\n",
      "                    full_ess = []\n",
      "                    full_p_vals = []\n",
      "                    shuff_ess = []\n",
      "                    shuff_p_vals = []\n",
      "                    \n",
      "                    # TODO This next part is pretty messy... it needs to get cleaned up.\n",
      "                    for permutation in permutations:\n",
      "                        # Collect results for full distance matrices.\n",
      "                        full_res_f = open(join(out_dir, study, 'bdiv_even%d' % depth, '%s_dm_%s_%s_%d' % (metric, method, category, permutation), '%s_results.txt' % method), 'U')\n",
      "                        full_es, full_p_val = res_parsing_fn(full_res_f)\n",
      "                        full_res_f.close()\n",
      "                        full_ess.append(full_es)\n",
      "                        full_p_vals.append(full_p_val)\n",
      "                        \n",
      "                        # Collect results for shuffled distance matrices.\n",
      "                        avg_shuff_ess = []\n",
      "                        avg_shuff_p_vals = []\n",
      "                        for shuff_num in range(1, num_shuffled + 1):\n",
      "                            shuff_res_f = open(join(out_dir, study, 'bdiv_even%d' % depth, '%s_dm_shuffled%d_%s_%s_%d' % (metric, shuff_num, method, category, permutation), '%s_results.txt' % method), 'U')\n",
      "                            shuff_es, shuff_p_val = res_parsing_fn(shuff_res_f)\n",
      "                            shuff_res_f.close()\n",
      "                            avg_shuff_ess.append(shuff_es)\n",
      "                            avg_shuff_p_vals.append(shuff_p_val)\n",
      "                        shuff_ess.append(median(avg_shuff_ess))\n",
      "                        shuff_p_vals.append(median(avg_shuff_p_vals))\n",
      "                        \n",
      "                    if len(set(full_ess)) != 1 or len(set(shuff_ess)) != 1:\n",
      "                        raise ValueError(\"The effect size statistics were not the same for different numbers of permutations. Something went wrong...\")\n",
      "                    for p_val in full_p_vals:\n",
      "                        if p_val < 0 or p_val > 1:\n",
      "                            raise ValueError(\"Encountered invalid p-value: %.4f\" % p_val)\n",
      "                    for p_val in shuff_p_vals:\n",
      "                        if p_val < 0 or p_val > 1:\n",
      "                            raise ValueError(\"Encountered invalid p-value: %.4f\" % p_val)\n",
      "                    category_res['full'] = (full_ess[0], full_p_vals)\n",
      "                    category_res['shuffled'] = (shuff_ess[0], shuff_p_vals)\n",
      "                        \n",
      "                    # Collect results for subsampled distance matrices.\n",
      "                    ss_ess = []\n",
      "                    ss_p_vals = []\n",
      "                    for group_size in group_sizes:\n",
      "                        gs_ess = []\n",
      "                        gs_p_vals = []\n",
      "                        \n",
      "                        for permutation in permutations:\n",
      "                            avg_ss_ess = []\n",
      "                            avg_ss_p_vals = []\n",
      "                            for ss_num in range(1, num_subsampled + 1):\n",
      "                                ss_res_f = open(join(out_dir, study, 'bdiv_even%d' % depth, '%s_dm_%s_ss%d_%d_%s_%s_%d' % (metric, category, group_size, ss_num, method, category, permutation),\n",
      "                                                     '%s_results.txt' % method), 'U')\n",
      "                                ss_es, ss_p_val = res_parsing_fn(ss_res_f)\n",
      "                                ss_res_f.close()\n",
      "                                avg_ss_ess.append(ss_es)\n",
      "                                avg_ss_p_vals.append(ss_p_val)\n",
      "                            gs_ess.append(median(avg_ss_ess))\n",
      "                            gs_p_vals.append(median(avg_ss_p_vals))\n",
      "                        \n",
      "                        if len(set(gs_ess)) != 1:\n",
      "                            raise ValueError(\"The effect size statistics were not the same for different numbers of permutations. Something went wrong...\")\n",
      "                        for p_val in gs_p_vals:\n",
      "                            if p_val < 0 or p_val > 1:\n",
      "                                raise ValueError(\"Encountered invalid p-value: %.4f\" % p_val)\n",
      "                        ss_ess.append(gs_ess[0])\n",
      "                        ss_p_vals.append(gs_p_vals)\n",
      "                    \n",
      "                    if len(ss_ess) != len(ss_p_vals):\n",
      "                        raise ValueError(\"We don't have the same number of effect size statistics as p-values. Something went wrong...\")\n",
      "                    category_res['subsampled'] = (ss_ess, ss_p_vals)\n",
      "                    \n",
      "                    study_res[category] = category_res\n",
      "                method_res[study] = study_res\n",
      "            metric_res[method] = method_res\n",
      "        depth_res[metric] = metric_res\n",
      "    results[depth_desc] = depth_res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Build results summary tables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Build tables to summarize the results of the statistical methods. These tables will be in TSV format so that they can be easily imported into Excel for viewing and cleanup for publication."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for depth_desc, depth_res in results.items():\n",
      "    for metric, metric_res in depth_res.items():\n",
      "        constructed_header = False\n",
      "        header = ['Method']\n",
      "        rows = []\n",
      "        for method, method_res in sorted(metric_res.items()):\n",
      "            row = ['%s' % method]\n",
      "            for study, study_res in sorted(method_res.items()):\n",
      "                for category, category_res in sorted(study_res.items()):\n",
      "                    # Format full results.\n",
      "                    header.append('%s\\r%s' % (study, category))\n",
      "                    row.append('%.2f; %s' % (category_res['full'][0], ', '.join(map(format_p_value_as_asterisk, category_res['full'][1]))))\n",
      "                    \n",
      "                    # Format shuffled results.\n",
      "                    header.append('%s\\r%s (shuffled)' % (study, category))\n",
      "                    row.append('%.2f; %s' % (category_res['shuffled'][0], ', '.join(map(format_p_value_as_asterisk, category_res['shuffled'][1]))))\n",
      "                    \n",
      "                    # Format subsampled results.\n",
      "                    header.append('%s\\r%s (subsampled)' % (study, category))\n",
      "                    cell = ['%.2f; %s' % (es, ', '.join(map(format_p_value_as_asterisk, p_vals))) for es, p_vals in zip(*category_res['subsampled'])]\n",
      "                    row.append('\\r'.join(cell))\n",
      "            if not constructed_header:\n",
      "                rows.append(header[:])\n",
      "                constructed_header = True\n",
      "            rows.append(row)\n",
      "        with open(join(out_dir, 'grouping_analysis_method_comparison_table_%s_%s.txt' % (depth_desc, metric)), 'wb') as out_f:\n",
      "            # We use \\r so that we can force linebreaks within cells when imported into Excel. Not sure if this will work with other spreadsheet programs such as Open Office.\n",
      "            tsv_writer = writer(out_f, delimiter='\\t', lineterminator='\\r')\n",
      "            tsv_writer.writerows(rows)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Sample size testing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Test the methods on subsets of the original sample groups. Samples will be chosen randomly without replacement to generate groups of samples at the specified subset size. A plot will be generated with subset size on the x-axis and test statistic on the y-axis. This will allow us to see if there is a cutoff/threshold based on the number of samples (i.e. where things start to stabilize in terms of the number of samples)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "from math import ceil\n",
      "from os.path import join\n",
      "from random import randint, shuffle\n",
      "from matplotlib.pyplot import errorbar, figure, legend, title, xlabel, xlim, ylabel\n",
      "from numpy import mean, std\n",
      "from qiime.filter import filter_samples_from_distance_matrix\n",
      "from qiime.parse import parse_distmat, parse_mapping_file_to_dict\n",
      "\n",
      "def run_cmd(cmd):\n",
      "    !$cmd\n",
      "\n",
      "group_sizes = [5, 10, 20, 40, 60, 80]\n",
      "num_subsets = 10\n",
      "study = 'whole_body'\n",
      "categories = {'BODY_SITE': ['b', 'Body site'], 'SEX': ['r', 'Sex']}\n",
      "even_depth = 575\n",
      "out_dir = '%s_grouping_analysis' % study\n",
      "grouping_methods = {\n",
      "                    'adonis': parse_adonis_results,\n",
      "                    'anosim': parse_anosim_permanova_results,\n",
      "                    'mrpp': parse_mrpp_results,\n",
      "                    'permanova': parse_anosim_permanova_results,\n",
      "                    'dbrda': parse_dbrda_results\n",
      "                   }\n",
      "\n",
      "map_fp = 'grouping_analysis_output/%s/map.txt' % study\n",
      "num_perms = 999"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!mkdir $out_dir\n",
      "cmds = []\n",
      "for category in categories:\n",
      "    for group_size in group_sizes:\n",
      "        for subset_num in range(1, num_subsets + 1):\n",
      "            map_f = open(map_fp, 'U')\n",
      "            dm_f = open('grouping_analysis_output/%s/bdiv_even%d/unweighted_unifrac_dm.txt' % (study, even_depth), 'U')\n",
      "            subset_dm_fp = join(out_dir, 'unweighted_unifrac_dm_%s_ss%d_%d.txt' % (category, group_size, subset_num))\n",
      "            subset_dm_f = open(subset_dm_fp, 'w')\n",
      "            subset_dm_f.write(subsample_dm(dm_f, map_f, category, group_size))\n",
      "            subset_dm_f.close()\n",
      "            dm_f.close()\n",
      "            map_f.close()\n",
      "            \n",
      "            for method in grouping_methods:\n",
      "                results_dir = join(out_dir, 'unweighted_unifrac_dm_%s_ss%d_%d_%s' % (category, group_size, subset_num, method))\n",
      "                cmds.append('compare_categories.py --method %s -n %d -i %s -m %s -c %s -o %s' % (method, num_perms, subset_dm_fp, map_fp, category, results_dir))\n",
      "                \n",
      "c = Client()\n",
      "dview = c[:]\n",
      "dview.block = True\n",
      "shuffle(cmds)\n",
      "out = dview.map(run_cmd, cmds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for method, parse_fn in grouping_methods.items():\n",
      "    fig = figure()\n",
      "    ax1 = fig.add_subplot(111)\n",
      "    ax2 = ax1.twinx()\n",
      "\n",
      "    for category, plot_options in categories.items():\n",
      "        avg_test_stats = []\n",
      "        std_test_stats = []\n",
      "        avg_p_vals = []\n",
      "        std_p_vals = []\n",
      "        \n",
      "        for group_size in group_sizes:\n",
      "            test_stats = []\n",
      "            p_vals = []\n",
      "            \n",
      "            for subset_num in range(1, num_subsets + 1):\n",
      "                results_dir = join(out_dir, 'unweighted_unifrac_dm_%s_ss%d_%d_%s' % (category, group_size, subset_num, method))\n",
      "                test_stat, p_val = parse_fn(open(join(results_dir, '%s_results.txt' % method), 'U'))\n",
      "                test_stats.append(test_stat)\n",
      "                p_vals.append(p_val)\n",
      "                \n",
      "            avg_test_stats.append(mean(test_stats))\n",
      "            std_test_stats.append(std(test_stats))\n",
      "            avg_p_vals.append(mean(p_vals))\n",
      "            std_p_vals.append(std(p_vals))\n",
      "            \n",
      "        # Plot test statistics on left axis.\n",
      "        ax1.errorbar(group_sizes, avg_test_stats, yerr=std_test_stats, color=plot_options[0], label=plot_options[1], fmt='-')\n",
      "        \n",
      "        # Plot p-values on the right axis.\n",
      "        ax2.errorbar(group_sizes, avg_p_vals, yerr=std_p_vals, color=plot_options[0], label=plot_options[1], fmt='-', linestyle='--')\n",
      "    \n",
      "    xlim(0, 85)\n",
      "    title('%s: %s' % (study, method))\n",
      "    ax1.set_xlabel('Samples per group')\n",
      "    ax1.set_ylabel('Average test statistic with standard deviation')\n",
      "    ax2.set_ylabel('Average p-value with standard deviation')\n",
      "    legend()\n",
      "    fig.savefig(join(out_dir, 'grouping_analysis_plot_%s_%s.pdf' % (study, method)), format='pdf')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Method Comparison Heatmap"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate a heatmap comparing every pair of *grouping analysis* methods using Pearson or Spearman correlation. For data, we will use all results of the original run of all even sampling depths, metrics, and datasets that match between the pair of methods."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "from matplotlib.pyplot import colorbar, figure, imshow, matshow, savefig, subplot, tight_layout, xticks, yticks\n",
      "from numpy import ones\n",
      "from cogent.maths.stats.test import pearson, spearman\n",
      "\n",
      "heatmap_methods = ['adonis', 'anosim', 'mrpp', 'permanova', 'dbrda']\n",
      "heatmap_method_labels = ['Adonis', 'ANOSIM', 'MRPP', 'PERMANOVA', 'db-RDA']\n",
      "\n",
      "# Gather all test statistics for each method (in the same order for each method!).\n",
      "method_data = defaultdict(list)\n",
      "for depth_desc, depth_res in results.items():\n",
      "    for metric, metric_res in depth_res.items():\n",
      "        for method, method_res in metric_res.items():\n",
      "            for study, study_res in sorted(method_res.items()):\n",
      "                for category, category_res in sorted(study_res.items()):\n",
      "                    method_data[method].append(category_res['full'][0])\n",
      "                    method_data[method].append(category_res['shuffled'][0])\n",
      "                    \n",
      "                    for es, p_vals in zip(*category_res['subsampled']):\n",
      "                        method_data[method].append(es)\n",
      "\n",
      "# Make sure our data looks sane... we should have the same number of observations for each method.\n",
      "data_length = None\n",
      "for method, data in method_data.items():\n",
      "    if data_length is None:\n",
      "        data_length = len(data)\n",
      "    elif len(data) != data_length:\n",
      "        raise ValueError(\"The number of test statistics is not the same between all methods, so we can't compare them! Something went wrong...\")\n",
      "\n",
      "# Compute the correlation coefficient between each pair of methods and put the output in an array. This array can then be used to generate a\n",
      "# text-based table or heatmap.\n",
      "for correlation_name, correlation_fn in ('pearson', pearson), ('spearman', spearman):\n",
      "    num_methods = len(heatmap_methods)\n",
      "    heatmap_data = ones((num_methods, num_methods))\n",
      "    \n",
      "    # I know this is inefficient, but it really doesn't matter for what we're doing here...\n",
      "    for method1_idx, method1 in enumerate(heatmap_methods):\n",
      "        for method2_idx, method2 in enumerate(heatmap_methods):\n",
      "            corr_coeff = correlation_fn(method_data[method1], method_data[method2])\n",
      "            heatmap_data[method1_idx][method2_idx] = corr_coeff\n",
      "            \n",
      "    # Generate the heatmap. Code based on http://matplotlib.org/users/tight_layout_guide.html and\n",
      "    # http://psaffrey.wordpress.com/2010/07/05/chromosome-interactions-heatmaps-and-matplotlib/\n",
      "    fig = figure()\n",
      "    ax = subplot(111)\n",
      "    im = ax.matshow(heatmap_data, vmin=0, vmax=1)\n",
      "    colorbar(im, use_gridspec=True)\n",
      "    xticks(range(len(heatmap_method_labels)), heatmap_method_labels, rotation=90)\n",
      "    yticks(range(len(heatmap_method_labels)), heatmap_method_labels)\n",
      "    tight_layout()\n",
      "    savefig('grouping_analysis_heatmap_0_1_%s.pdf' % correlation_name, format='pdf')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tight_layout : falling back to Agg renderer\n",
        "tight_layout : falling back to Agg renderer"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# For testing...\n",
      "f1 = [\"Method Name\\tR-value\\tP-value\\n\", \"ANOSIM\\t0.463253142506\\t0.01\\n\"]\n",
      "a, b = parse_anosim_permanova_results(f1)\n",
      "print a\n",
      "print b\n",
      "print ''\n",
      "\n",
      "f1 = \"\"\"\n",
      "Call:\n",
      "adonis(formula = as.dist(qiime.data$distmat) ~ qiime.data$map[[opts$category]],      permutations = opts$num_permutations) \n",
      "\n",
      "                                Df SumsOfSqs MeanSqs F.Model      R2 Pr(>F)   \n",
      "qiime.data$map[[opts$category]]  6     6.635 1.10591  3.2632 0.20273   0.01 **\n",
      "Residuals                       77    26.096 0.33891         0.79727          \n",
      "Total                           83    32.731                 1.00000          \n",
      "---\n",
      "Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\"\"\".split('\\n')\n",
      "\n",
      "a, b = parse_adonis_results(f1)\n",
      "print a\n",
      "print b\n",
      "print ''\n",
      "\n",
      "f1 = \"\"\"\n",
      "Call:\n",
      "mrpp(dat = as.dist(qiime.data$distmat), grouping = qiime.data$map[[opts$category]],      permutations = opts$num_permutations) \n",
      "\n",
      "Dissimilarity index: \n",
      "Weights for groups:  n \n",
      "\n",
      "Class means and counts:\n",
      "\n",
      "      ENVO:forest ENVO:grassland ENVO:shrubland\n",
      "delta 0.8133      0.8758         0.8456        \n",
      "n     13          6              20            \n",
      "      ENVO:Temperate broadleaf and mixed forest biome ENVO:Temperate grasslands\n",
      "delta 0.7626                                          0.8554                   \n",
      "n     19                                              11                       \n",
      "      ENVO:Tropical and subtropical grasslands, savannas, and shrubland biome\n",
      "delta 0.8392                                                                 \n",
      "n     3                                                                      \n",
      "      ENVO:Tropical humid forests\n",
      "delta 0.7835                     \n",
      "n     12                         \n",
      "\n",
      "Chance corrected within-group agreement A: 0.07567 \n",
      "Based on observed delta 0.8162 and expected delta 0.883 \n",
      "\n",
      "Significance of delta: 0.01 \n",
      "Based on  99  permutations\n",
      "\"\"\".split('\\n')\n",
      "\n",
      "a, b = parse_mrpp_results(f1)\n",
      "print a\n",
      "print b\n",
      "print ''\n",
      "\n",
      "f1 = \"\"\"Call: capscale(formula = as.dist(qiime.data$distmat) ~ factor, data =\n",
      "factors.frame)\n",
      "\n",
      "               Inertia Proportion Rank\n",
      "Total         159.1762                \n",
      "Real Total    165.4413     1.0000     \n",
      "Constrained    46.0873     0.2786   19\n",
      "Unconstrained 119.3540     0.7214  371\n",
      "Imaginary      -6.2651             213\n",
      "Inertia is squared Unknown distance \n",
      "\n",
      "Eigenvalues for constrained axes:\n",
      "    CAP1     CAP2     CAP3     CAP4     CAP5     CAP6     CAP7     CAP8 \n",
      "14.72239 10.95891  8.89776  3.26489  2.89957  1.41151  0.87627  0.69475 \n",
      "    CAP9    CAP10    CAP11    CAP12    CAP13    CAP14    CAP15    CAP16 \n",
      " 0.40960  0.35446  0.29999  0.24395  0.20137  0.18342  0.17567  0.15110 \n",
      "   CAP17    CAP18    CAP19 \n",
      " 0.13347  0.11498  0.09327 \n",
      "\n",
      "Eigenvalues for unconstrained axes:\n",
      "  MDS1   MDS2   MDS3   MDS4   MDS5   MDS6   MDS7   MDS8 \n",
      "12.480  5.688  4.495  3.722  3.331  2.814  2.279  2.153 \n",
      "(Showed only 8 of all 371 unconstrained eigenvalues)\n",
      "\n",
      "\n",
      "Permutation test for capscale \n",
      "\n",
      "Call: capscale(formula = as.dist(qiime.data$distmat) ~ factor, data =\n",
      "factors.frame)\n",
      "Permutation test for all constrained eigenvalues\n",
      "Pseudo-F:\t 11.48258 (with 19, 565 Degrees of Freedom)\n",
      "Significance:\t 0.010101 \n",
      "Based on 98 permutations under reduced model.\n",
      "\"\"\".split('\\n')\n",
      "\n",
      "r2, p_val = parse_dbrda_results(f1)\n",
      "print r2\n",
      "print p_val\n",
      "print ''\n",
      "\n",
      "f1 = \"\"\"Analysis of Variance Table\n",
      "\n",
      "Response: Distances\n",
      "           Df Sum Sq   Mean Sq F value Pr(>F)\n",
      "Groups      1 0.0119 0.0118769  2.0989 0.1479\n",
      "Residuals 583 3.2990 0.0056587               \n",
      "\n",
      "Permutation test for homogeneity of multivariate dispersions\n",
      "\n",
      "No. of permutations: 999  \n",
      "\n",
      "**** STRATA ****\n",
      "Permutations are unstratified\n",
      "\n",
      "**** SAMPLES ****\n",
      "Permutation type: free \n",
      "Mirrored permutations for Samples?: No \n",
      "\n",
      "Response: Distances\n",
      "           Df Sum Sq   Mean Sq      F N.Perm Pr(>F)\n",
      "Groups      1 0.0119 0.0118769 2.0989    999  0.131\n",
      "Residuals 583 3.2990 0.0056587                     \n",
      "\n",
      "Pairwise comparisons:\n",
      "(Observed p-value below diagonal, permuted p-value above diagonal)\n",
      "        female  male\n",
      "female         0.132\n",
      "male   0.14794  \n",
      "\"\"\".split('\\n')\n",
      "\n",
      "f_val, p_val = parse_permdisp_results(f1)\n",
      "print f_val\n",
      "print p_val\n",
      "print ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.463253142506"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.01\n",
        "\n",
        "0.20273\n",
        "0.01\n",
        "\n",
        "0.07567\n",
        "0.01\n",
        "\n",
        "0.2786\n",
        "0.010101\n",
        "\n",
        "2.0989\n",
        "0.131\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    }
   ],
   "metadata": {}
  }
 ]
}