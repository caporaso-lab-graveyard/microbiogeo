{
 "metadata": {
  "name": "biogeo_analysis"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Set up workflow parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Configure the variables in this section to control how the workflow will be executed. For example, what studies to analyze, categories of interest, etc.."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "from csv import writer\n",
      "from os.path import basename, join, splitext\n",
      "from random import sample\n",
      "\n",
      "from numpy import mean\n",
      "\n",
      "from qiime.filter import filter_samples_from_distance_matrix\n",
      "from qiime.parse import parse_distmat\n",
      "from qiime.util import MetadataMap\n",
      "\n",
      "test = True\n",
      "\n",
      "if test:\n",
      "    in_dir = 'test_datasets'\n",
      "    out_dir = 'test_output'\n",
      "    tree_fp = join('test_datasets', 'overview', 'rep_set.tre')\n",
      "    depth_descs = ['5_percent', '25_percent', '50_percent']\n",
      "    studies = {\n",
      "               'overview': {\n",
      "                            'depths': [50, 100, 146],\n",
      "                            'categories': ['Treatment'],\n",
      "                            'group_sizes': [3, 4]\n",
      "                           }\n",
      "              }\n",
      "    metrics = ['euclidean', 'bray_curtis']\n",
      "    grouping_methods = {\n",
      "                        'adonis': parse_adonis_results,\n",
      "                        'anosim': parse_anosim_permanova_results\n",
      "                       }\n",
      "    permutations = [99, 999]\n",
      "    num_shuffled = 2\n",
      "    num_subsampled = 2\n",
      "    jobs_to_start = 2\n",
      "else:\n",
      "    in_dir = 'datasets'\n",
      "    out_dir = 'output'\n",
      "    tree_fp = join('gg_otus_4feb2011', 'trees', 'gg_97_otus_4feb2011.tre')\n",
      "    depth_descs = ['5_percent', '25_percent', '50_percent']\n",
      "    studies = {\n",
      "               '88_soils': {\n",
      "                            'depths': [400, 580, 660],\n",
      "                            'categories': ['ENV_BIOME'],\n",
      "                            'group_sizes': [5, 10, 20, 40]\n",
      "                           }, \n",
      "               'glen_canyon': {\n",
      "                               'depths': [15000, 29000, 53000],\n",
      "                               'categories': ['CurrentlyWet'],\n",
      "                               'group_sizes': [5, 10, 20, 40]\n",
      "                              },\n",
      "               'keyboard': {\n",
      "                            'depths': [390, 780, 1015],\n",
      "                            'categories': ['HOST_SUBJECT_ID'],\n",
      "                            'group_sizes': [5, 10, 20, 40]\n",
      "                           },\n",
      "               'whole_body': {\n",
      "                              'depths': [575, 877, 1110],\n",
      "                              'categories': ['BODY_SITE', 'SEX'],\n",
      "                              'group_sizes': [5, 10, 20, 40]\n",
      "                             }\n",
      "              }\n",
      "    metrics = ['euclidean', 'bray_curtis', 'weighted_unifrac', 'unweighted_unifrac']\n",
      "    grouping_methods = {\n",
      "                        'adonis': parse_adonis_results,\n",
      "                        'anosim': parse_anosim_permanova_results,\n",
      "                        'mrpp': parse_mrpp_results,\n",
      "                        'permanova': parse_anosim_permanova_results,\n",
      "                        'rda': parse_rda_results\n",
      "                       }\n",
      "    permutations = [99, 999, 9999]\n",
      "    num_shuffled = 3\n",
      "    num_subsampled = 3\n",
      "    jobs_to_start = 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Generate distance matrices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate distance matrices for each study at even sampling depths that exclude 5%, 25%, and 50% of the samples from the input OTU table (these numbers were calculated beforehand). Generate Euclidean, Bray-Curtis, weighted UniFrac, and unweighted UniFrac distance matrices at each sampling depth using the GreenGenes 97% tree. Also generate several shuffled versions of each distance matrix, which can be used later as negative controls.\n",
      "\n",
      "In addition, generate several subsampled versions of each distance matrix to control the size of each group of samples (based on a category), which can be used later to test how the methods perform on different study sizes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def subsample_dm(dm_f, map_f, category, group_size):\n",
      "    metadata_map = MetadataMap.parseMetadataMap(map_f)\n",
      "    category_map = defaultdict(list)\n",
      "    for samp_id in metadata_map.SampleIds:\n",
      "        category_val = metadata_map.getCategoryValue(samp_id, category)\n",
      "        category_map[category_val].append(samp_id)\n",
      "    \n",
      "    samp_ids_to_keep = []\n",
      "    for category_val, samp_ids in category_map.items():\n",
      "        samp_ids_to_keep.extend(sample(samp_ids, group_size))\n",
      "    return filter_samples_from_distance_matrix(parse_distmat(dm_f), samp_ids_to_keep, negate=True)\n",
      "\n",
      "!mkdir $out_dir\n",
      "for study in studies:\n",
      "    in_study_dir = join(in_dir, study)\n",
      "    out_study_dir = join(out_dir, study)\n",
      "    !mkdir $out_study_dir\n",
      "    !cp $in_study_dir/map.txt $out_study_dir/\n",
      "    map_fp = join(out_study_dir, 'map.txt')\n",
      "    \n",
      "    for depth in studies[study]['depths']:\n",
      "        full_otu_fp = join(in_study_dir, 'otu_table.biom')\n",
      "        even_otu_fp = join(out_study_dir, 'otu_table_even%d.biom' % depth)\n",
      "        bdiv_out_dir = join(out_study_dir, 'bdiv_even%d' % depth)\n",
      "        \n",
      "        metrics_param = ','.join(metrics)\n",
      "        !single_rarefaction.py -i $full_otu_fp -o $even_otu_fp -d $depth\n",
      "        !parallel_beta_diversity.py -i $even_otu_fp -o $bdiv_out_dir -m $metrics_param -T -t $tree_fp -O $jobs_to_start\n",
      "        \n",
      "        # Rename each file to match QIIME's standard naming conventions of distance matrices. Generate shuffled versions of each distance matrix.\n",
      "        for metric in metrics:\n",
      "            dm_fp = join(bdiv_out_dir, '%s_otu_table_even%d.txt' % (metric, depth))\n",
      "            renamed_dm_fp = join(bdiv_out_dir, '%s_dm.txt' % metric)\n",
      "            !mv $dm_fp $renamed_dm_fp\n",
      "            for i in range(1, num_shuffled + 1):\n",
      "                shuffled_dm_fp = join(bdiv_out_dir, '%s_dm_shuffled%d.txt' % (metric, i))\n",
      "                !shuffle_distance_matrix.py -i $renamed_dm_fp -o $shuffled_dm_fp\n",
      "            \n",
      "            # Create subsampled distance matrices.\n",
      "            for category in studies[study]['categories']:\n",
      "                for group_size in studies[study]['group_sizes']:\n",
      "                    for i in range(1, num_subsampled + 1):\n",
      "                        subsampled_dm_fp = join(bdiv_out_dir, '%s_dm_%s_ss%d_%d.txt' % (metric, category, group_size, i))\n",
      "                        subsampled_dm = open(subsampled_dm_fp, 'w')\n",
      "                        subsampled_dm.write(subsample_dm(open(renamed_dm_fp, 'U'), open(map_fp, 'U'), category, group_size))\n",
      "                        subsampled_dm.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Run grouping analysis methods"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run each *grouping analysis* statistical method on each distance matrix. These are methods that test out categorical variables such as sex, individual, body site, etc.."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# There is some crazy nesting here, may need to break out into separate functions later on.\n",
      "for study in studies:\n",
      "    study_dir = join(out_dir, study)\n",
      "    map_fp = join(study_dir, 'map.txt')\n",
      "    categories = studies[study]['categories']\n",
      "    \n",
      "    for depth in studies[study]['depths']:\n",
      "        depth_dir = join(study_dir, 'bdiv_even%d' % depth)\n",
      "        dm_wildcard = join(depth_dir, '*_dm*.txt')\n",
      "        dm_fps = !ls $dm_wildcard\n",
      "        \n",
      "        for dm_fp in dm_fps:\n",
      "            for method in grouping_methods:\n",
      "                for category in categories:\n",
      "                    for permutation in permutations:\n",
      "                        dm_bn = basename(dm_fp)\n",
      "                        if 'dm.txt' in dm_bn or 'dm_shuffled' in dm_bn or 'dm_%s_ss' % category in dm_bn:\n",
      "                            results_dir = join(depth_dir, '%s_%s_%s_%d' % (splitext(dm_bn)[0], method, category, permutation))\n",
      "                            !compare_categories.py --method $method -n $permutation -i $dm_fp -m $map_fp -c $category -o $results_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Collate results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Parse and collect the effect size statistics and p-values from each of the tests that were run. The resulting data structure can then be used to format result tables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define functions to parse effect size statistics and p-values from the various results files.\n",
      "def parse_anosim_permanova_results(results_f):\n",
      "    for line in results_f:\n",
      "        pass\n",
      "    es, p_value = map(float, line.strip().split('\\t')[1:])\n",
      "    if p_value < 0 or p_value > 1:\n",
      "        raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "    return es, p_values\n",
      "\n",
      "def parse_adonis_results(results_f):\n",
      "    for line in results_f:\n",
      "        if line.startswith('qiime.data$map[[opts$category]]'):\n",
      "            tokens = line.strip().split()\n",
      "            if len(tokens) == 7:\n",
      "                es, p_value = map(float, line.strip().split()[-2:])\n",
      "                if p_value < 0 or p_value > 1:\n",
      "                    raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "                elif es < 0 or es > 1:\n",
      "                    raise ValueError(\"Encountered invalid R2 value: %.4f\" % es)\n",
      "                return es, p_value\n",
      "            elif len(tokens) == 8:\n",
      "                es, p_value = map(float, line.strip().split()[:-1][-2:])\n",
      "                if p_value < 0 or p_value > 1:\n",
      "                    raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "                elif es < 0 or es > 1:\n",
      "                    raise ValueError(\"Encountered invalid R2 value: %.4f\" % es)\n",
      "                return es, p_value\n",
      "            else:\n",
      "                raise ValueError(\"Encountered unparsable line: %s\" % line)\n",
      "        \n",
      "def parse_mrpp_results(results_f):\n",
      "    for line in results_f:\n",
      "        if line.startswith('Chance corrected within-group agreement A:'):\n",
      "            a_value = float(line.strip().split()[-1])\n",
      "        elif line.startswith('Significance of delta:'):\n",
      "            p_value = float(line.strip().split()[-1])\n",
      "    \n",
      "    if p_value < 0 or p_value > 1:\n",
      "        raise ValueError(\"Encountered invalid p-value: %.4f\" % p_value)\n",
      "    return a_value, p_value\n",
      "\n",
      "def parse_rda_results(results_f):\n",
      "    for line in results_f:\n",
      "        if line.startswith('Constrained'):\n",
      "            # RDA does not have a p-value.\n",
      "            es, p_value = float(line.strip().split()[2]), None\n",
      "            if es < 0 or es > 1:\n",
      "                raise ValueError(\"Encountered invalid R2 value: %.4f\" % es)\n",
      "            return es, p_value\n",
      "    \n",
      "results = {}\n",
      "for depth_idx, depth_desc in enumerate(depth_descs):\n",
      "    depth_res = {}\n",
      "    for metric in metrics:\n",
      "        metric_res = {}\n",
      "        for method, res_parsing_fn in grouping_methods.items():\n",
      "            method_res = {}\n",
      "            for study in studies:\n",
      "                study_res = {}\n",
      "                \n",
      "                # Figure out what our actual depth is for the study.\n",
      "                depth = studies[study]['depths'][depth_idx]\n",
      "                for category in studies[study]['categories']:\n",
      "                    category_res = {}\n",
      "                    full_ess = []\n",
      "                    full_p_vals = []\n",
      "                    shuff_ess = []\n",
      "                    shuff_p_vals = []\n",
      "                    for permutation in permutations:\n",
      "                        # Collect results for full distance matrices.\n",
      "                        full_res_f = open(join(out_dir, study, 'bdiv_even%d' % depth, '%s_dm_%s_%s_%d' % (metric, method, category, permutation), '%s_results.txt' % method), 'U')\n",
      "                        full_es, full_p_val = res_parsing_fn(full_res_f)\n",
      "                        full_res_f.close()\n",
      "                        full_ess.append(full_es)\n",
      "                        full_p_vals.append(full_p_val)\n",
      "                        \n",
      "                        # Collect results for shuffled distance matrices.\n",
      "                        avg_shuff_ess = []\n",
      "                        avg_shuff_p_vals = []\n",
      "                        for shuff_num in range(1, num_shuffled + 1):\n",
      "                            shuff_res_f = open(join(out_dir, study, 'bdiv_even%d' % depth, '%s_dm_shuffled%d_%s_%s_%d' % (metric, shuff_num, method, category, permutation), '%s_results.txt' % method), 'U')\n",
      "                            shuff_es, shuff_p_val = res_parsing_fn(shuff_res_f)\n",
      "                            shuff_res_f.close()\n",
      "                            avg_shuff_ess.append(shuff_es)\n",
      "                            avg_shuff_p_vals.append(shuff_p_val)\n",
      "                        shuff_ess.append(mean(avg_shuff_ess))\n",
      "                        shuff_p_vals.append(mean(avg_shuff_p_vals))\n",
      "                    \n",
      "                    if len(set(full_ess)) != 1 or len(set(shuff_ess)) != 1:\n",
      "                        raise ValueError(\"The effect size statistics were not the same for different numbers of permutations. Something went wrong...\")\n",
      "                    for p_val in full_p_vals:\n",
      "                        if p_val < 0 or p_val > 1:\n",
      "                            raise ValueError(\"Encountered invalid p-value: %.4f\" % p_val)\n",
      "                    for p_val in shuff_p_vals:\n",
      "                        if p_val < 0 or p_val > 1:\n",
      "                            raise ValueError(\"Encountered invalid p-value: %.4f\" % p_val)\n",
      "                            \n",
      "                    category_res['full'] = (full_ess[0], full_p_vals)\n",
      "                    category_res['shuffled'] = (shuff_ess[0], shuff_p_vals)\n",
      "                    study_res[category] = category_res\n",
      "                method_res[study] = study_res\n",
      "            metric_res[method] = method_res\n",
      "        depth_res[metric] = metric_res\n",
      "    results[depth_desc] = depth_res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Build results summary tables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Build tables to summarize the results of the statistical methods. These tables will be in TSV format so that they can be easily imported into Excel for viewing and cleanup for publication."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def format_p_value_as_asterisk(p_value):\n",
      "    # p_value should be a float\n",
      "    result = 'x'\n",
      "    if p_value <= 0.1:\n",
      "        result = '*'\n",
      "    if p_value <= 0.05:\n",
      "        result += '*'\n",
      "    if p_value <= 0.01:\n",
      "        result += '*'\n",
      "    if p_value <= 0.001:\n",
      "        result += '*'\n",
      "    return result\n",
      "\n",
      "for depth_desc, depth_res in results.items():\n",
      "    for metric, metric_res in depth_res.items():\n",
      "        constructed_header = False\n",
      "        header = ['Method']\n",
      "        rows = []\n",
      "        for method, method_res in sorted(metric_res.items()):\n",
      "            row = ['%s' % method]\n",
      "            for study, study_res in sorted(method_res.items()):\n",
      "                for category, category_res in sorted(study_res.items()):\n",
      "                    # Format full results.\n",
      "                    header.append('%s\\r%s' % (study, category))\n",
      "                    row.append('%.2f; %s' % (category_res['full'][0], ', '.join(map(format_p_value_as_asterisk, category_res['full'][1]))))\n",
      "                    \n",
      "                    # Format shuffled results.\n",
      "                    header.append('%s\\r%s (shuffled)' % (study, category))\n",
      "                    row.append('%.2f; %s' % (category_res['shuffled'][0], ', '.join(map(format_p_value_as_asterisk, category_res['shuffled'][1]))))\n",
      "            if not constructed_header:\n",
      "                rows.append(header[:])\n",
      "                constructed_header = True\n",
      "            rows.append(row)\n",
      "        with open(join(out_dir, 'method_comparison_table_%s_%s.txt' % (depth_desc, metric)), 'wb') as out_f:\n",
      "            # We use \\r so that we can force linebreaks within cells when imported into Excel.\n",
      "            tsv_writer = writer(out_f, delimiter='\\t', lineterminator='\\r')\n",
      "            tsv_writer.writerows(rows)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# For testing...\n",
      "f1 = [\"Method Name\\tR-value\\tP-value\\n\", \"ANOSIM\\t0.463253142506\\t0.01\\n\"]\n",
      "a, b = parse_anosim_permanova_results(f1)\n",
      "print a\n",
      "print b\n",
      "print ''\n",
      "\n",
      "f1 = \"\"\"\n",
      "Call:\n",
      "adonis(formula = as.dist(qiime.data$distmat) ~ qiime.data$map[[opts$category]],      permutations = opts$num_permutations) \n",
      "\n",
      "                                Df SumsOfSqs MeanSqs F.Model      R2 Pr(>F)   \n",
      "qiime.data$map[[opts$category]]  6     6.635 1.10591  3.2632 0.20273   0.01 **\n",
      "Residuals                       77    26.096 0.33891         0.79727          \n",
      "Total                           83    32.731                 1.00000          \n",
      "---\n",
      "Signif. codes:  0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1\"\"\".split('\\n')\n",
      "\n",
      "a, b = parse_adonis_results(f1)\n",
      "print a\n",
      "print b\n",
      "print ''\n",
      "\n",
      "f1 = \"\"\"\n",
      "Call:\n",
      "mrpp(dat = as.dist(qiime.data$distmat), grouping = qiime.data$map[[opts$category]],      permutations = opts$num_permutations) \n",
      "\n",
      "Dissimilarity index: \n",
      "Weights for groups:  n \n",
      "\n",
      "Class means and counts:\n",
      "\n",
      "      ENVO:forest ENVO:grassland ENVO:shrubland\n",
      "delta 0.8133      0.8758         0.8456        \n",
      "n     13          6              20            \n",
      "      ENVO:Temperate broadleaf and mixed forest biome ENVO:Temperate grasslands\n",
      "delta 0.7626                                          0.8554                   \n",
      "n     19                                              11                       \n",
      "      ENVO:Tropical and subtropical grasslands, savannas, and shrubland biome\n",
      "delta 0.8392                                                                 \n",
      "n     3                                                                      \n",
      "      ENVO:Tropical humid forests\n",
      "delta 0.7835                     \n",
      "n     12                         \n",
      "\n",
      "Chance corrected within-group agreement A: 0.07567 \n",
      "Based on observed delta 0.8162 and expected delta 0.883 \n",
      "\n",
      "Significance of delta: 0.01 \n",
      "Based on  99  permutations\n",
      "\"\"\".split('\\n')\n",
      "\n",
      "a, b = parse_mrpp_results(f1)\n",
      "print a\n",
      "print b\n",
      "print ''\n",
      "\n",
      "f1 = \"\"\"Call: capscale(formula = as.dist(qiime.data$distmat) ~ factor, data =\n",
      "factors.frame)\n",
      "\n",
      "              Inertia Proportion Rank\n",
      "Total         32.7314     1.0000     \n",
      "Constrained    6.6355     0.2027    6\n",
      "Unconstrained 26.0959     0.7973   77\n",
      "Inertia is squared Unknown distance \n",
      "\n",
      "Eigenvalues for constrained axes:\n",
      "  CAP1   CAP2   CAP3   CAP4   CAP5   CAP6 \n",
      "3.1868 1.4512 0.7006 0.6076 0.3928 0.2965 \n",
      "\n",
      "Eigenvalues for unconstrained axes:\n",
      "  MDS1   MDS2   MDS3   MDS4   MDS5   MDS6   MDS7   MDS8 \n",
      "3.0187 1.6909 1.3803 1.0177 0.8587 0.7774 0.7537 0.6264 \n",
      "(Showed only 8 of all 77 unconstrained eigenvalues)\n",
      "\"\"\".split('\\n')\n",
      "r2, p_val = parse_rda_results(f1)\n",
      "print r2\n",
      "print ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Run gradient analysis methods"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run each *gradient analysis* statistical method on each distance matrix. These are methods that test out continuous variables such as pH, latitude, etc.."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}